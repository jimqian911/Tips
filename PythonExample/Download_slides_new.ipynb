{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "* [here](https://null-byte.wonderhowto.com/how-to/download-all-pdfs-webpage-with-python-script-0163031/)\n",
    "* [here](https://stackoverflow.com/questions/7243750/download-file-from-web-in-python-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as urllib\n",
    "import urllib3\n",
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllibR\n",
    "from requests import get\n",
    "from time import sleep, time\n",
    "import re\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to download (bypass using firefox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def obtain_bs4soup(url, bypass):\n",
    "    try:\n",
    "        os.mkdir(download_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    }\n",
    "    \n",
    "    ## Choose whether to bypass through firefox\n",
    "    if bypass == True:\n",
    "        request0 = urllibR.Request(url=url, headers=headers)\n",
    "        request = urllibR.urlopen(request0)\n",
    "    else:\n",
    "        request = urllibR.urlopen(url)\n",
    "        \n",
    "    soup = BeautifulSoup(request.read(), \"lxml\")\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "def download(url, file_name):\n",
    "    # open in binary mode\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        try:\n",
    "            # get request\n",
    "            response = get(url)\n",
    "            # write to file\n",
    "            file.write(response.content)\n",
    "        except:\n",
    "            print(\"fail\", file_name)\n",
    "#         print(\"wrote\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "url = \"http://people.tamu.edu/~aglass/econ452/\"\n",
    "# url = \"https://projects.iq.harvard.edu/prefresher/math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "download_path = \"/Users/tomoyasasaki/Documents/Materials/Lectures/InterEcon452_Glass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "if not os.path.exists(download_path):\n",
    "    os.makedirs(download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "soup = obtain_bs4soup(url, bypass = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ec452SylS17.pdf\n",
      "Student%20Registration%20Handout%20for%20glass51079.pdf\n",
      "TUTORING%20LAB%20Fall%202016.pdf\n",
      "Private%20Tutors%202013C.pdf\n",
      "WTO%20World%20Trade%20Report%202008.pdf\n",
      "WTO%20World%20Trade%20Report%202008%20Executive%20Summary.pdf\n",
      "Krugman01_10eHandout.pdf\n",
      "Krugman01_10eHandout.pdf\n",
      "Krugman01_10e.pdf\n",
      "WTO%20World%20Trade%20Report%202008%20Globalization%20and%20Trade.pdf\n",
      "Going%20under.pdf\n",
      "Fragile%20Web%20of%20Foreign%20Trade.pdf\n",
      "Ceglowski_BordlessWorld.pdf\n",
      "Total%20Trade%20to%20GDP.pdf\n",
      "Total%20Trade%20to%20GDP%20Bar.pdf\n",
      "index.html\n",
      "FRBD%20Texas%20Exports%20Top%20Spot%20swe0601d.pdf\n",
      "FRBD%20Texas%20Exports%20Growing%20Faster%20swe0702d.pdf\n",
      "FRBD%20Globalizing%20Texas%20swe0705c.pdf\n",
      "krugman02.pdf\n",
      "Krugman02_10eHandout.pdf\n",
      "Krugman02.pdf\n",
      "Krugman02_10e.pdf\n",
      "Econ452%20Notation%20for%20Ricardian%20Model.pdf\n",
      "WTO%20World%20Trade%20Report%202008%20Causes%20of%20Trade.pdf\n",
      "Economist2a.pdf\n",
      "Economist2c.pdf\n",
      "Economist2b.pdf\n",
      "brma98sg.pdf\n",
      "NYT_Economic%20Scene_%20What%20Happen.pdf\n",
      "trefler_MacDonaldCommission_2005.pdf\n",
      "Krugman03_10eHandout.pdf\n",
      "Krugman03_10e.pdf\n",
      "Problems3.pdf\n",
      "Problems3.pdf\n",
      "Hints%20for%20Economics%20452%20Problem%20Set%20One.pdf\n",
      "E452Review3.pdf\n",
      "E452Review3.pdf\n",
      "RicardianEquil.pdf\n",
      "E452exs1S14a.pdf\n",
      "E452exs1F14a.pdf\n",
      "E452exs1S15a.pdf\n",
      "E452exs1F15a.pdf\n",
      "E452exs1S16a.pdf\n",
      "E452exs1F16a.pdf\n",
      "E452exs1S17a.pdf\n",
      "E452exs1S17b.pdf\n",
      "WTO%20World%20Trade%20Report%202008%20Causes%20of%20Trade.pdf\n",
      "Pew%20Mexican%20Immigrants%20112.pdf\n",
      "The%20Immigration%20Equation.pdf\n",
      "JEEA2008.pdf\n",
      "Aid%20workers%20who%20realy%20help.pdf\n",
      "Krugman04.pdf\n",
      "Krugman04Slides.pdf\n",
      "chapter_4.pdf\n",
      "WTO%20World%20Trade%20Report%202008%20Causes%20of%20Trade.pdf\n",
      "WTO%20World%20Trade%20Report%202008%20Trade%20and%20Inequality.pdf\n",
      "WTO%20World%20Trade%20Report%202008%20Social%20Consequences.pdf\n",
      "Economist4b.pdf\n",
      "LowTechMadeinUSA.pdf\n",
      "Rich%20man%20poor%20man.pdf\n",
      "Shadow%20of%20prosperity.pdf\n",
      "Krugmans%20conundrum.pdf\n",
      "Economist4c.pdf\n",
      "Krugman05.pdf\n",
      "Krugman05Slides.pdf\n",
      "Problems5.pdf\n",
      "Problems4.pdf\n",
      "Hints%20for%20Economics%20452%20Problem%20Set%20Two.pdf\n",
      "E452Review4.pdf\n",
      "Factor%20Proportions%20Model.pdf\n",
      "Krugman06.pdf\n",
      "Krugman06Slides.pdf\n",
      "International%20Transfers.pdf\n",
      "E452exs2S14a.pdf\n",
      "E452exs2F14a.pdf\n",
      "E452exs2S15a.pdf\n",
      "E452exs2F15a.pdf\n",
      "E452exs2S16a.pdf\n",
      "E452exs2F16a.pdf\n",
      "E452exs2S17a.pdf\n",
      "E452exs2S17b.pdf\n",
      "FRBD%20Border%20Employment%20fotexas_canas.pdf\n",
      "FRBD%20Border%20Employment%20fotexas_canas.pdf\n",
      "FRBD%20Maquiladoras%20Changing%20Geography%20swe0902c.pdf\n",
      "FRBDstaff0801.pdf\n",
      "Krugman08FDI.pdf\n",
      "Krugman08FDISlides.pdf\n",
      "E452FDIExtraCredit.pdf\n",
      "Economist8b.pdf\n",
      "Economist8c.pdf\n",
      "Economist8d.pdf\n",
      "Why%20Trade%20Talks%20Collapsed%20WSJ%202008.pdf\n",
      "Nuts%20and%20Bolts%20Come%20Apart.pdf\n",
      "Unpredictable%20Tides.pdf\n",
      "Irwin%20halt%20spread%20protectionism.pdf\n",
      "Economic%20Vandalism.pdf\n",
      "FRBD%20Did%20NAFTA%20Spur%20Texas%20Exports%20%20swe0602b.pdf\n",
      "FRBD%20Did%20NAFTA%20Spur%20Texas%20Exports%20%20swe0602b.pdf\n",
      "Doing%20Doha%20Down.pdf\n",
      "Noodle%20bowl.pdf\n",
      "Krugman09.pdf\n",
      "Krugman09Slides.pdf\n",
      "Problems9.pdf\n",
      "Problems8.pdf\n",
      "Hints%20for%20Economics%20452%20Problem%20Set%20Three.pdf\n",
      "E452Review8.pdf\n",
      "Tariff%20problems.pdf\n",
      "MakingCaseTradeWSJ2016.pdf\n",
      "Krugman10.pdf\n",
      "Krugman09Slides.pdf\n",
      "Krugman10Slides.pdf\n",
      "E452exs3S14b.pdf\n",
      "E452exs3F14a.pdf\n",
      "E452exs3S15a.pdf\n",
      "E452exs3F15a.pdf\n",
      "E452exs3S16a.pdf\n",
      "E452exs3F16a.pdf\n"
     ]
    }
   ],
   "source": [
    "## if the URL for the target file is straight forward, use this\n",
    "## e.g. <a href=\"/path/to/file.pdf\">\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    if os.path.splitext(os.path.basename(tag2))[1] == \".pdf\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".ipynb\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".py\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".tex\" or\\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".zip\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".ppt\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".RData\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".html\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".R\" or \\\n",
    "    os.path.splitext(os.path.basename(tag2))[1] == \".txt\":\n",
    "\n",
    "#     if len( os.path.splitext(os.path.basename(tag2))[1]  ) >= 1:\n",
    "        name = os.path.basename(tag2)\n",
    "#         name = os.path.basename(tag2)[:-2]\n",
    "        download(tag2, name)\n",
    "        print(name)\n",
    "        sleep(1)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics1_2017\n",
      "metrics2_2017\n",
      "metrics3_2017\n",
      "metrics4_2017\n",
      "metrics5_2017\n",
      "metrics6_2017\n"
     ]
    }
   ],
   "source": [
    "## if the URL for the target file is NOT straight forward, use this\n",
    "## e.g. <a href=\"path/to/file.pdf?attredirects=0&amp;d=1\">\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    if \".pdf\" in os.path.splitext(os.path.basename(tag2))[1]:\n",
    "        name = os.path.splitext(os.path.basename(tag2))[0]\n",
    "        download(tag2, name + \".pdf\")\n",
    "        print(name)\n",
    "        sleep(1)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scratch\n",
    "\n",
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "#     print(os.path.splitext(os.path.basename(tag['href'])) )\n",
    "#     print(tag2)\n",
    "#     if os.path.splitext(os.path.basename(tag2))[1] == \".pdf\" or os.path.splitext(os.path.basename(tag2))[1] == \".r\"\\\n",
    "    if \".xls\" in os.path.splitext(os.path.basename(tag2))[1]:\n",
    "#         print(tag2)\n",
    "#         name = os.path.basename(tag2)[:-2]\n",
    "        name = os.path.splitext(os.path.basename(tag2))[0]\n",
    "#         download(tag2, name)\n",
    "        download(tag2, name + \".xls\")\n",
    "        print(name)\n",
    "#         if name == \"sig_phrases_det.pdf\":\n",
    "#             pass\n",
    "#         else:\n",
    "#         download(tag2, re.sub(r\"\\?.+\" ,\"\",os.path.basename(tag2) ))\n",
    "#         download(url + name, name)\n",
    "#         sleep(1)\n",
    "#         tmp.append(tag2)\n",
    "\n",
    "# end = time()\n",
    "# elapse = end - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/?C=N;O=D\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/?C=M;O=A\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/?C=S;O=A\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/?C=D;O=A\n",
      "https://www.stat.washington.edu/people/pdhoff/Book/Data/\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/XY.tumor\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/Y.mathscore\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/Y.pima.full\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/Y.pima.miss\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/Y.reading\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/Y.school.mathscore\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/Y.tumor\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/alldata\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/chapter7.r\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/chapter8.r\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/chapter9.r\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/chapter10.r\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/chapter11.r\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/ids_selectschools\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/mathdat\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/nels_2002\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/readme.txt\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/vostok.1999.temp.dat\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/vostok.icecore.co2.dat\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/y.school1\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/y.school2\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/yX.diabetes.test\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/yX.diabetes.train\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/yX.o2uptake\n",
      "https://www.stat.washington.edu/~pdhoff/Book/Data/data/yX.sparrow\n"
     ]
    }
   ],
   "source": [
    "os.chdir(download_path)\n",
    "for tag in soup.findAll('a', href = True):\n",
    "    tag2 = urllibR.urljoin(url, tag['href'])\n",
    "    print(tag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
